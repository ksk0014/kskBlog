<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[离职工作总结]]></title>
    <url>%2FkskBlog%2F2018%2F05%2F07%2F%E7%A6%BB%E8%81%8C%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[2015.8.5 刚从台湾交换学习回大陆，当时周边的同学大都已经找好了实习工作，当时以为自己被就业市场抛弃了，慌慌张张的到处投简历，也拿到一些简历，最先拿到的是B厂的测试研发岗，好歹占了一个研发字样，就毫不犹豫的过去了。说实话，当时很鄙视做测试的，感觉一点技术含量都没，low。虽然后续也拿到猫厂的offer，但由于拥抱变化被降薪，果断拒了。 在熊厂将近一年的实习时间里，学到了很多，测试不是一份low的工作，是另一种思维的工作，从用户角度度量产品质量，这是一种能力，它涵盖了研发人员普遍认为不重要或者潜意识里被忽视的方方面面，形象的比喻就是研发人员是低着头做事，测试人员是抬着头做事。由于还算认真的实习历练，老板X认可了我，转正之后，就开始独立负责一个项目的测试工作，也开始带了一些员工。遇到了一些新的挑战，在负责一个项目时，和之前做小弟时候不一样，各种事情都需要你操心，需要和老板汇报、和研发团队确认事务排期、和PM确认产品需求排期、和依赖服务确认进度，各种协调性的事务压的没有时间去思考自己到底学了什么？在带新人的时候，得考虑如何给每个人恰到好处的安排工作，得看到这个人惰性集中在哪个地方，然后“鞭策”他回到正确的轨道。带新人有成功的案例也有失败的案例，这给我在接下来面试新人的时候带来很多对于人的潜力的认知，受益无穷。在这个阶段，我认识到了一个团队的重要性，在这里我要很隆重的感谢在我项目组里的R同学，她真正让我理解了什么是1 + 1 &gt; 2，个人英雄主义最多能支持走一时，团队才持久战的必要因素之一。秉持着这份信念，在接下来的1年多时间里，拿遍了所有体系内的个人奖项，不过很可惜，由于团队规模不大，没有得到团队的奖项。 随着手中事务越做越重复，突然发现自己一天比一天轻松，即使是承接新项目测试，也没给我带来多大的动力，因为对于测试来说，一成不变的东西几乎占到日常工作的80%，加之碰到了个人和公司氛围的一些困境，工作越来越觉得无聊。还是简单吐槽一下吧，个人方面，因为进公司以后负责的更多是单一领域的测试工作，看到的面窄，觉得限制了自身的成长，于是自己提出了一套整个产品栈的测试方案，方案整体获得了经理和高工的支持，但无奈啊上下游协作的团队太短视，以为自己的饼会被抢了一样，极度不配合。我也是个嫉恶如仇的人，厌恶这种小肚鸡肠的作风，然后就互相给小鞋呗（这里我承认我的处理不够大气），anyway，哥就是这样的人。再说说公司氛围，给我的感觉是没有一种传承的传统，产品平台半年或者一年就会因为各种原因被抛弃，总需要新平台，述职才会好看嘛，更多的人不会去想想怎么把一个产品持续的打磨下去。还有一个问题，经常会有人吐槽度厂没有PM，其实更多的给我的感觉是，研发人员地位太牢靠了，只会低着头想自己的事，很少会见到主动去找研发以为的人沟通设计，更多的被动的接受外部的建议，然后看“心情”做不做，虽然说的有点过，但在我接触到的周边项目基本上是这样了。再说公司层面的战略问题，一年一个样，百度云虽然说是有ABC战略支撑，但是给我感觉老板并没有过多重视这个方向，没有气魄去砸人力物力（例如腾讯那样），导致现在在市场上第二梯队苦苦挣扎。算了，少吐槽一些，毕竟我在这里也学到了很多，遇到了很多靠谱的人。 再说说找工作吧，也是很奇妙，因为我是测试的身份，想要找一份研发的工作，很难，不被各个公司认可，一度无望的时候，猫厂抛来了橄榄枝，除了猫厂的HR有点不靠谱以外（offer拖了一个多月才发），面试官总体给我的感觉是不错的，严谨认真负责，很感激god给我安排这第二份工作，给了自己一份重新清零的机会，重新审视一下自己，真正想要什么、有什么、能做什么，希望能在新的岗位上，开启事业的第二春！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统部署工具]]></title>
    <url>%2FkskBlog%2F2018%2F05%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[背景分布式集群搭建通常具体以下几个难点: 具有复杂的机器拓扑结构 配置管理错综复杂 模块之间的启动顺序有着强依赖 模块版本变更由于跨机器十分不便 集群外部系统依赖复杂且难以管理 对于一套可以简洁易用的中控式搭建、初始化、变更、监控集群的部署工具有强需求，可以提高小型开发团队在系统迭代阶段的效率 功能 根据集群拓扑结构的规划自动搭建整套集群 提供自定义配置、变更配置功能 自动处理好外部系统依赖的初始化工作，如mysql系统的建库建表 自动完成本系统的环境初始化工作 自动生成全集群各模块的启停及状态监控脚本 代码结构代码路径: https://github.com/ksk0014/distributed-systems-deploy 下载下来后会有三个目录: conf目录: 模块配置文件, machine.xxx代表集群拓扑结构规划 bin目录: 集群部署、升级脚本 auto-deploy-cluster: 主运行程序，模板目录 conf说明 文件 说明 cluster.conf 搭建的所有配置,在文件中有详细注释 diy.conf 模块自定义配置，端口类的配置可以忽略，此类配置系统会自动分配得出 machine.xxx 某个模板需要搭建的机器, 每一行表示一个机器 数据结构模板数据组织结构如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788group = &#123; &quot;instances&quot;: [ &amp;instance1, &amp;instance2 ]&#125;region = &#123;&#125;#同group #搭建的某个实例instance = &#123;&quot;name&quot;: str, #唯一标识某个搭建模块的名字&quot;dir_name&quot;: str, #在机器上的部署目录,同一模块在同一机器上部署多个时该值不一样&quot;app_type&quot;: str, #见application中的name&quot;on_machine&quot;: str, #机器名,与machine中的name对应&quot;group&quot;: int, #暂时未用&quot;region&quot;: int, #fileserver 的region标识&quot;idx&quot;: int, #该模块的第几个实例,&quot;idx_in_group&quot;: int, #在group中该实例的index&quot;machine_ref&quot;: &amp;&#123;machine&#125;, #见machine数据结构&quot;application_ref&quot;: &amp;&#123;application&#125;, #见application数据结构&quot;group_ref&quot;: &amp;&#123;group&#125;, #见group数据结构&quot;region_ref&quot;: &amp;&#123;region&#125;, #见region数据结构&quot;idx_in_region&quot;: int, #region中该实例的index&quot;ports&quot;: &#123; &quot;port_name&quot;: int, #port_name来源于application中的port_name,根据不同的模块而不一样 ...&#125;,&quot;region_name&quot;: str&#125;#固定数据结构,数据中每个元素表示某一个模块,即一个applicationapplications = [&#123; #一个application &quot;name&quot;: &quot;xxx|yyy|zzz&quot;, &quot;dir_tmpl&quot;: str, #模板目录,一般不会用到, &quot;port_names&quot;: [&quot;xx_port&quot;, &quot;xx_port&quot;], #不同的模块的port_name不一样,可查看代码 &quot;idx&quot;: int, #一般不会用到 &quot;instances&quot;: [&amp;instance], #模块的instance列表 &quot;group_with_name&quot;: &#123; &quot;group_name&quot;: &amp;group, #group_name是一个int值 ... &#125;, &quot;region_with_name&quot;:&#123; &quot;region_name&quot;: &amp;region, #同上 &#125;, &quot;groups&quot;: [&amp;group], #group的列表, &quot;region&quot;: [&amp;region], #region的列表&#125;,&#123;...&#125;] #搭建的机器信息machines = [&#123; &quot;name&quot;: str, #机器标识,不一定是机器名,与instance中的on_machine对应 &quot;deploy__address&quot;: str, #格式为user_name@machine_host这种格式 &quot;deploy__dest_dir&quot;: str, #在机器上的搭建目录 &quot;ip&quot;: str, #机器ip &quot;user_name&quot;: str, #机器用户名 &quot;pass&quot;: str, #机器密码 &quot;idx&quot;: int, #机器的index &quot;instances&quot;: [&amp;instance], #机器上搭建的instance列表&#125;] #几个全局变量machine_with_name = &#123; &quot;name&quot;: &amp;machine, &quot;name2&quot;: &amp;machine, ...&#125; application_with_name = &#123; &quot;name&quot;: &amp;application, ...&#125; group_with_name = &#123; &quot;name&quot;: &amp;group&#125; region_with_name = &#123; &quot;name&quot;: &amp;region&#125; 使用部署集群: 设计拓扑结构 完成模块配置设定 bin目录下执行 install.sh, 等待集群安装完毕 更新集群: 修改集群配置，及模块配置 bin目录下执行 upgrade.sh module_name, 等待更新完毕 集群中控: 部署完毕生成shell目录，支持模块级别的启停、存活状态、机器资源耗费的检查]]></content>
      <categories>
        <category>部署工具</category>
      </categories>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储质量保障体系]]></title>
    <url>%2FkskBlog%2F2018%2F05%2F04%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E8%B4%A8%E9%87%8F%E4%BF%9D%E9%9A%9C%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[测试流程代码review –&gt; UT（L1）–&gt; L2（简单功能测试）–&gt; L3（全量回归测试）–&gt; 异常环境 –&gt; 集成测试 –&gt; 性能测试 –&gt; 自动上线 –&gt; 线上灰度测试 测试流程功能简述代码review：主要是代码规范性检查，coding风格、代码书写合理性（项目高工查），测试人员需要关注log打印是否合理、是否有冗余或缺失、日志级别是否合理 UT：auto trigger，UT测试代码由研发人员负责编写，测试人员需要维护UT测试环境、推动单测问题解决、推动单测覆盖率提升 L2：auto trigger，测试用例为全量测试中的一小部分，测试时长在30分钟以内，目的是快速发现CI代码在基本接口功能上面存在的问题，及时推动研发人员解决 L3：daily build，全量测试，考察代码在复杂场景下、单个异常下运行情况，测试时间应当在12h以内，测试问题第二天及时反馈RD解决，问题绝不过夜 failover：hand trigger，全量回归三轮无异常，版本拉分支进入异常环境，多种异常混合、持续压力、异常预案演练、集群服务能力评估，运行三天无问题，产出测试报告 集成测试：hand trigger upgrade，failover环境三天无问题，版本进入集成环境，版本兼容性测试、上下游模块对接测试，观察三天 性能测试：hand trigger，集成环境三天无异常，开始集群性能测试，观察版本间性能是否存在回退，如存在推动定位调优，产出性能测试报告 自动上线：hand trigger，借助变更平台上线 线上灰度测试：版本上线时触发，代码相对简单，测试需要关注的是平台维护、报警信息补全完善 新patch测试须知 功能设计阶段：参与设计讨论 功能开发阶段：与研发功能确认接口，开发对应测试用例，编写测试方案设计文档 功能提测阶段：review功能实现逻辑，最好能看懂业务逻辑层面的代码，调通新增测试用例，加入回归测试 功能验收阶段：稳定回归3轮，有问题及时推动解决，问题绝不过夜，及时更新测试进度记录文档 分支测试阶段：功能验收通过，推入failover环境，有问题及时推动解决，产出测试报告 集成环境观察阶段：上线集成环境，观察兼容性、联调上下游环境、性能回退，产出测试报告 最后上线阶段：冒烟测试]]></content>
      <categories>
        <category>测试设计</category>
      </categories>
      <tags>
        <tag>Testing Framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[块存储性能测试]]></title>
    <url>%2FkskBlog%2F2018%2F05%2F04%2F%E5%9D%97%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[业务需求块存储服务推出后，需要针对各种产品宣称性能做基准性能评估。存储领域中性能评估指标主要分为三类IOPS、throughput、latency 目前业界对于块存储的产品划分情况如下: 产品类型 性能特点 应用场景 主流厂商支持情况 near local &gt;= 本地ssd盘性能 大型OLTP数据库/NoSQL数据库/ELK分布式日志 阿里云ESSD SSD云盘 20000IOPS左右 I/O密集型应用/中型关系数据库/NoSQL数据库 主流厂商均支持 高效云盘 性能够用就好，5000IOPS左右 开发与测试业务/小型负载数据库/系统盘 主流厂商均支持 普通云盘 sata介质，吞吐优化型500MBps，冷存储250MBps以下 大数据/数据仓库/日志处理 aws划分更细致，阿里云已淘汰 分层测试框架分布式块存储性能测试考量需要覆盖以下的层次: 系统网络性能、物理磁盘性能测试 存储核心系统读写性能测试，stress_tool、data_consistency_tool 宿主机上云盘性能、以及虚拟机上的云盘性能，PTS测试模型，fio 设备上文件系统性能测试，filebench，iozone等等 实际应用负载测试，sysbench OLTP、分布式数据分析框架IO负载仿真 用户常用操作的易用性 块存储性能测试需要从两个视角看： 用户维度：针对系统中单一卷实例可以获得稳定且可预期的性能，更多关注上述3 ~ 6的测试层次，本文主要讲解第3个层次的测试设计 集群维度：针对集群可服务能力的性能评估，保障系统整体稳定可控，更多关注上述1 ~ 2的测试层次 PTS测试模型PTS： Solid State Storage Performance Test SpecificationSNIA固态存储性能测试标准，相关文档参见 SSS_PTS_2.0.1.pdf 本文测试设计主要参考上述文档，并针对云环境做了相应适配 测试步骤根据 PTS 规范，SSD 性能测试需要经过以下四个步骤： 净化（purge）：通过擦除数据，将 SSD 置于接近 FOB 状态。 事先准备工作负载（WIPC）：写入规定的数据到整个 SSD，帮助其达到稳态。 正式测试之前的准备工作（WDPC）：循环运行测试，直到 SSD 进入稳态。 测试：当 SSD 进入稳态时开始测试。 备注: FOB: Fresh of Box，新鲜出盒，即硬盘刚买来的状态稳态: 性能波动范围小于预先设定的阈值 测试项IOPS测试测试在不同block size与不同的read/write 比的混合下随机IO的性能block size：100/0, 95/5, 65/35, 50/50, 35/65, 5/95, 0/100read/write：1024KiB, 128KiB, 64KiB, 32KiB, 16KiB, 8KiB, 4KiB, 0.5KiB磁盘IO的范围：100% volume size （1）purge（2）WIPC：128k顺序写2倍的磁盘空间（3）WDPC：上述工作负载（bs，r/w） loop运行（4）稳态判定：取相邻4轮的4kb 随机 0/100的iops，相对均值上下浮动在10%以内，即达到稳态，即取这四轮的测试数据为稳态窗口 测试数据，取稳态窗口的均值 Throughput测试测试在稳态的128k与1m的顺序读与顺序写的吞吐磁盘IO的范围：100% volume size （1）purge（2）WIPC：128k顺序写或1M的顺序写2倍的磁盘空间（3）WDPC：bs(128k,1M)和rw(100/0, 0/100) 顺序IO，loop，记录吞吐量（4）稳态判定：取相邻4轮的吞吐，相对均值上下浮动在10%以内，即达到稳态，即取这四轮的测试数据为稳态窗口 测试数据，取稳态窗口的均值 延迟测试测试在3种block sizes（0.5k，4k和8k），与三种读/写 比（100/0，65/35，0/100）混合下IO响应时间磁盘IO的范围：100% volume size （1）purge（2）WIPC：128k顺序写2倍的磁盘空间（3）WDPC：bs(0.5k, 4k, 8k)和rw(100/0, 65/35, 0/100) 随机IO，loop，记录最大延迟与平均延迟（4）稳态判定：取相邻4轮的平均延迟（0/100，4k），相对均值上下浮动在10%以内，即达到稳态，即取这四轮的测试数据为稳态窗口 测试数据，取稳态窗口的均值 稳定性测试测试SSD性能是随着时间以及写入量的增加是如何变化的（1min的检测穿插着30分钟的WAST测试） （1）purge（2）4k的随机写（100%），持续写入达到4倍的磁盘大小或者达到24h或者达到5轮的稳态（满足其一即可）（3）iostat统计磁盘读写性能数据，取fio延迟波动方差的数据 测试工具代码路径: https://github.com/ksk0014/block-storage-benchamrk 效果展示测试结果保存在文件中，格式如下图:]]></content>
      <categories>
        <category>测试设计</category>
      </categories>
      <tags>
        <tag>Testing Phase</tag>
      </tags>
  </entry>
</search>
